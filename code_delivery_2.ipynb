{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJt5ExOYaZWt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1. Compute log returns and correlation\n",
        "\n",
        "def compute_log_returns(price_df):\n",
        "    # Return log price differences.\n",
        "    log_prices = np.log(price_df)\n",
        "    return log_prices.diff().dropna()\n",
        "\n",
        "\n",
        "def compute_correlation_matrix(returns_df):\n",
        "    # Return correlation matrix of returns.\n",
        "    return returns_df.corr()\n",
        "\n",
        "# 2. MST and clustering\n",
        "\n",
        "class UnionFind:\n",
        "    def __init__(self, items):\n",
        "        self.parent = {x: x for x in items}\n",
        "        self.rank = {x: 0 for x in items}\n",
        "\n",
        "    def find(self, x):\n",
        "        if self.parent[x] != x:\n",
        "            self.parent[x] = self.find(self.parent[x])\n",
        "        return self.parent[x]\n",
        "\n",
        "    def union(self, a, b):\n",
        "        ra, rb = self.find(a), self.find(b)\n",
        "        if ra == rb:\n",
        "            return False\n",
        "\n",
        "        if self.rank[ra] < self.rank[rb]:\n",
        "            self.parent[ra] = rb\n",
        "        elif self.rank[ra] > self.rank[rb]:\n",
        "            self.parent[rb] = ra\n",
        "        else:\n",
        "            self.parent[rb] = ra\n",
        "            self.rank[ra] += 1\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "def build_mst_from_corr(corr_matrix):\n",
        "    # Build an MST using distance = 1 - correlation.\n",
        "    names = list(corr_matrix.columns)\n",
        "    edges = []\n",
        "\n",
        "    # collect distances\n",
        "    for i in range(len(names)):\n",
        "        for j in range(i+1, len(names)):\n",
        "            a, b = names[i], names[j]\n",
        "            # cite the below line from AI\n",
        "            c = corr_matrix.loc[a, b]\n",
        "            edges.append((1 - c, a, b, c))\n",
        "\n",
        "    edges.sort(key=lambda x: x[0])\n",
        "\n",
        "    uf = UnionFind(names)\n",
        "    mst = []\n",
        "\n",
        "    for dist, a, b, c in edges:\n",
        "        if uf.union(a, b):\n",
        "            mst.append((a, b, c, dist))\n",
        "\n",
        "    return mst\n",
        "\n",
        "\n",
        "def clusters_from_mst(mst_edges, corr_threshold=0.5):\n",
        "    # Form clusters by removing low-correlation edges.\n",
        "    graph = {}\n",
        "    nodes = set()\n",
        "\n",
        "    for a, b, c, _ in mst_edges:\n",
        "        nodes.add(a)\n",
        "        nodes.add(b)\n",
        "        if c >= corr_threshold:\n",
        "            # cite the below 2 lines from AI\n",
        "            graph.setdefault(a, []).append(b)\n",
        "            graph.setdefault(b, []).append(a)\n",
        "\n",
        "    for n in nodes:\n",
        "        graph.setdefault(n, [])\n",
        "\n",
        "    visited = set()\n",
        "    groups = []\n",
        "\n",
        "    # find connected components\n",
        "    for n in nodes:\n",
        "        if n not in visited:\n",
        "            stack = [n]\n",
        "            comp = []\n",
        "            visited.add(n)\n",
        "\n",
        "            while stack:\n",
        "                x = stack.pop()\n",
        "                comp.append(x)\n",
        "                for y in graph[x]:\n",
        "                    if y not in visited:\n",
        "                        visited.add(y)\n",
        "                        stack.append(y)\n",
        "\n",
        "            groups.append(comp)\n",
        "\n",
        "    return groups\n",
        "\n",
        "# 3. Visualization\n",
        "\n",
        "def plot_mst_graph(mst_edges, clusters):\n",
        "    # Draw MST on a circle layout.\n",
        "    nodes = [n for g in clusters for n in g]\n",
        "    N = len(nodes)\n",
        "\n",
        "    # cite the below 2 lines from AI\n",
        "    angles = np.linspace(0, 2*np.pi, N, endpoint=False)\n",
        "    pos = {nodes[i]: (np.cos(angles[i]), np.sin(angles[i])) for i in range(N)}\n",
        "\n",
        "    colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple',\n",
        "              'tab:brown','tab:pink','tab:gray','tab:olive','tab:cyan']\n",
        "\n",
        "    node_color = {}\n",
        "    for idx, g in enumerate(clusters):\n",
        "        for name in g:\n",
        "            # cite the below line from AI\n",
        "            node_color[name] = colors[idx % len(colors)]\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "\n",
        "    for a, b, _, _ in mst_edges:\n",
        "        x1, y1 = pos[a]\n",
        "        x2, y2 = pos[b]\n",
        "        plt.plot([x1, x2], [y1, y2], color='lightgray', linewidth=0.6)\n",
        "\n",
        "    for name, (x, y) in pos.items():\n",
        "        # edited the below 2 line with AI's help\n",
        "        plt.scatter(x, y, color=node_color[name], s=45)\n",
        "        plt.text(x, y, name, fontsize=7, ha='center', va='center')\n",
        "\n",
        "    plt.title(\"MST (Clustered)\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_cluster_time_series(price_df, clusters):\n",
        "    # Plot price histories for each cluster.\n",
        "    for i, group in enumerate(clusters):\n",
        "        plt.figure(figsize=(8,4))\n",
        "        for ticker in group:\n",
        "            if ticker in price_df.columns:\n",
        "                plt.plot(price_df.index, price_df[ticker], label=ticker)\n",
        "\n",
        "        plt.title(f\"Cluster {i+1}\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Price\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Compute log returns and correlation\n",
        "\n",
        "def compute_log_returns(price_df):\n",
        "    # Return log price differences for each stock.\n",
        "    log_prices = np.log(price_df)\n",
        "    returns = log_prices.diff().dropna()\n",
        "    return returns\n",
        "\n",
        "\n",
        "def compute_correlation_matrix(returns_df):\n",
        "    # Return correlation matrix of returns.\n",
        "    return returns_df.corr()\n",
        "\n",
        "# 2. Union-Find and MST construction\n",
        "\n",
        "# refer to Lauren's code in lecture and HW\n",
        "class UnionFind:\n",
        "    def __init__(self, items):\n",
        "        self.parent = {x: x for x in items}\n",
        "        self.rank = {x: 0 for x in items}\n",
        "\n",
        "    def find(self, x):\n",
        "        # path compression\n",
        "        if self.parent[x] != x:\n",
        "            self.parent[x] = self.find(self.parent[x])\n",
        "        return self.parent[x]\n",
        "\n",
        "    def union(self, a, b):\n",
        "        # union by rank\n",
        "        root_a = self.find(a)\n",
        "        root_b = self.find(b)\n",
        "\n",
        "        if root_a == root_b:\n",
        "            return False\n",
        "\n",
        "        if self.rank[root_a] < self.rank[root_b]:\n",
        "            self.parent[root_a] = root_b\n",
        "        elif self.rank[root_a] > self.rank[root_b]:\n",
        "            self.parent[root_b] = root_a\n",
        "        else:\n",
        "            self.parent[root_b] = root_a\n",
        "            self.rank[root_a] += 1\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "def build_mst_from_corr(corr_matrix):\n",
        "\n",
        "    # Build an MST using distance = 1 - correlation.\n",
        "    names = list(corr_matrix.columns)\n",
        "    edges = []\n",
        "\n",
        "    # collect pairwise distances\n",
        "    for i in range(len(names)):\n",
        "        for j in range(i + 1, len(names)):\n",
        "            a = names[i]\n",
        "            b = names[j]\n",
        "\n",
        "            # cite the below line from AI\n",
        "            c = corr_matrix.loc[a, b]\n",
        "            dist = 1 - c\n",
        "            edges.append((dist, a, b, c))\n",
        "\n",
        "    # Kruskal: sort by distance\n",
        "    edges.sort(key=lambda x: x[0])\n",
        "\n",
        "    uf = UnionFind(names)\n",
        "    mst_edges = []\n",
        "\n",
        "    for dist, a, b, c in edges:\n",
        "        if uf.union(a, b):\n",
        "            mst_edges.append((a, b, c, dist))\n",
        "\n",
        "    return mst_edges\n",
        "\n",
        "# 3. Clustering from MST\n",
        "\n",
        "def clusters_from_mst(mst_edges, corr_threshold=0.5):\n",
        "\n",
        "    # Form clusters by removing edges whose correlation is below corr_threshold.\n",
        "    graph = {}\n",
        "    nodes = set()\n",
        "\n",
        "    for a, b, c, dist in mst_edges:\n",
        "        nodes.add(a)\n",
        "        nodes.add(b)\n",
        "        if c >= corr_threshold:\n",
        "            # edited the below 2 lines with AI\n",
        "            graph.setdefault(a, []).append(b)\n",
        "            graph.setdefault(b, []).append(a)\n",
        "\n",
        "    for n in nodes:\n",
        "        graph.setdefault(n, [])\n",
        "\n",
        "    visited = set()\n",
        "    clusters = []\n",
        "\n",
        "    for start in nodes:\n",
        "        if start in visited:\n",
        "            continue\n",
        "\n",
        "        stack = [start]\n",
        "        visited.add(start)\n",
        "        comp = []\n",
        "\n",
        "        while stack:\n",
        "            x = stack.pop()\n",
        "            comp.append(x)\n",
        "            for y in graph[x]:\n",
        "                if y not in visited:\n",
        "                    visited.add(y)\n",
        "                    stack.append(y)\n",
        "\n",
        "        clusters.append(comp)\n",
        "\n",
        "    return clusters\n",
        "\n",
        "# 4. Cluster summary statistics (new)\n",
        "\n",
        "def summarize_clusters(corr_matrix, clusters):\n",
        "    \"\"\"\n",
        "    For each cluster, compute some simple stats.\n",
        "    Returns a DataFrame with:\n",
        "      - size\n",
        "      - mean correlation\n",
        "      - min correlation\n",
        "      - max correlation\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, group in enumerate(clusters):\n",
        "        # submatrix for this cluster\n",
        "        # cite the below line from AI\n",
        "        sub = corr_matrix.loc[group, group]\n",
        "\n",
        "        # drop diagonal\n",
        "        # edited the below 2 lines with AI\n",
        "        mask = ~np.eye(len(sub), dtype=bool)\n",
        "        vals = sub.values[mask]\n",
        "\n",
        "        if len(vals) == 0:\n",
        "            avg_corr = np.nan\n",
        "            min_corr = np.nan\n",
        "            max_corr = np.nan\n",
        "        else:\n",
        "            avg_corr = float(np.nanmean(vals))\n",
        "            min_corr = float(np.nanmin(vals))\n",
        "            max_corr = float(np.nanmax(vals))\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"cluster_id\": i,\n",
        "                \"size\": len(group),\n",
        "                \"mean_corr\": avg_corr,\n",
        "                \"min_corr\": min_corr,\n",
        "                \"max_corr\": max_corr,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # cite the below line from AI\n",
        "    summary_df = pd.DataFrame(rows)\n",
        "    return summary_df\n",
        "\n",
        "# 5. Visualization: MST + time series\n",
        "\n",
        "def _build_circle_layout(clusters):\n",
        "    # Helper: place nodes evenly on a circle.\n",
        "    nodes = [n for group in clusters for n in group]\n",
        "    n = len(nodes)\n",
        "    # cite the below line from AI\n",
        "    angles = np.linspace(0, 2 * np.pi, n, endpoint=False)\n",
        "\n",
        "    positions = {}\n",
        "    for i, name in enumerate(nodes):\n",
        "        # cite the below 2 lines from AI\n",
        "        x = np.cos(angles[i])\n",
        "        y = np.sin(angles[i])\n",
        "        positions[name] = (x, y)\n",
        "    return positions\n",
        "\n",
        "\n",
        "def plot_mst_graph(mst_edges, clusters, title=\"MST (clustered)\"):\n",
        "    # Draw MST on a circle layout, colored by cluster.\n",
        "    pos = _build_circle_layout(clusters)\n",
        "\n",
        "    palette = [\n",
        "        \"tab:blue\",\n",
        "        \"tab:orange\",\n",
        "        \"tab:green\",\n",
        "        \"tab:red\",\n",
        "        \"tab:purple\",\n",
        "        \"tab:brown\",\n",
        "        \"tab:pink\",\n",
        "        \"tab:gray\",\n",
        "        \"tab:olive\",\n",
        "        \"tab:cyan\",\n",
        "    ]\n",
        "\n",
        "    color_map = {}\n",
        "    for idx, group in enumerate(clusters):\n",
        "        # cite the below line from AI\n",
        "        color = palette[idx % len(palette)]\n",
        "        for name in group:\n",
        "            color_map[name] = color\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "\n",
        "    # draw edges\n",
        "    for a, b, c, dist in mst_edges:\n",
        "        x1, y1 = pos[a]\n",
        "        x2, y2 = pos[b]\n",
        "        plt.plot([x1, x2], [y1, y2], color=\"lightgray\", linewidth=0.6)\n",
        "\n",
        "    # draw nodes\n",
        "    for name, (x, y) in pos.items():\n",
        "        # edited the below 2 lines with AI\n",
        "        plt.scatter(x, y, color=color_map.get(name, \"black\"), s=45)\n",
        "        plt.text(x, y, name, fontsize=7, ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_cluster_time_series(price_df, clusters):\n",
        "    # Plot the price history for each cluster.\n",
        "    for i, group in enumerate(clusters):\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for name in group:\n",
        "            if name in price_df.columns:\n",
        "                plt.plot(price_df.index, price_df[name], label=name)\n",
        "\n",
        "        plt.title(f\"Cluster {i + 1}\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Price\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# 6. Heatmap visualization  (new)\n",
        "\n",
        "def plot_correlation_heatmap(corr_matrix, title=\"Correlation heatmap\", labels=True):\n",
        "    # Simple heatmap of the correlation matrix.\n",
        "\n",
        "    # cite the below line from AI\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(corr_matrix.values, origin=\"lower\",\n",
        "               cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "    plt.colorbar(label=\"Correlation\")\n",
        "\n",
        "    if labels:\n",
        "        names = list(corr_matrix.columns)\n",
        "        ticks = range(len(names))\n",
        "        plt.xticks(ticks, names, rotation=90, fontsize=6)\n",
        "        plt.yticks(ticks, names, fontsize=6)\n",
        "    else:\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_clustered_heatmap(corr_matrix, clusters, title=\"Clustered correlation\"):\n",
        "    # Reorder the correlation matrix by cluster membership.\n",
        "    # Draw a heatmap to show block structure.\n",
        "\n",
        "    ordered = []\n",
        "    for group in clusters:\n",
        "        for name in group:\n",
        "            if name in corr_matrix.columns:\n",
        "                ordered.append(name)\n",
        "\n",
        "    # just in case some names were not in any cluster list\n",
        "    for name in corr_matrix.columns:\n",
        "        if name not in ordered:\n",
        "            ordered.append(name)\n",
        "\n",
        "    reordered = corr_matrix.loc[ordered, ordered]\n",
        "    plot_correlation_heatmap(reordered, title=title, labels=True)\n",
        "\n",
        "# 7. Rolling-window analysis  (new)\n",
        "\n",
        "def make_time_windows(price_df, window_size, step):\n",
        "    # Build a list of (start_idx, end_idx) windows.\n",
        "    # window_size and step are in number of rows.\n",
        "\n",
        "    n = len(price_df)\n",
        "    windows = []\n",
        "    start = 0\n",
        "\n",
        "    while start + window_size <= n:\n",
        "        end = start + window_size\n",
        "        windows.append((start, end))\n",
        "        start += step\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def run_single_window(price_df, start, end, corr_threshold=0.6):\n",
        "    # Run the full pipeline on one time window.\n",
        "\n",
        "    # cite the below 6 lines from AI\n",
        "    window_prices = price_df.iloc[start:end]\n",
        "    returns = compute_log_returns(window_prices)\n",
        "    corr = compute_correlation_matrix(returns)\n",
        "    mst = build_mst_from_corr(corr)\n",
        "    clusters = clusters_from_mst(mst, corr_threshold=corr_threshold)\n",
        "    summary = summarize_clusters(corr, clusters)\n",
        "\n",
        "    return {\n",
        "        \"corr\": corr,\n",
        "        \"mst\": mst,\n",
        "        \"clusters\": clusters,\n",
        "        \"summary\": summary,\n",
        "        \"start\": window_prices.index[0],\n",
        "        \"end\": window_prices.index[-1],\n",
        "    }\n",
        "\n",
        "\n",
        "def rolling_window_analysis(price_df, window_size, step, corr_threshold=0.6):\n",
        "    # Run the MST + clustering analysis over rolling windows.\n",
        "    # Returns a list of window_results dicts.\n",
        "\n",
        "    windows = make_time_windows(price_df, window_size, step)\n",
        "    results = []\n",
        "\n",
        "    for start, end in windows:\n",
        "        # cite the below line from AI\n",
        "        info = run_single_window(price_df, start, end,\n",
        "                                 corr_threshold=corr_threshold)\n",
        "        results.append(info)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_window_summaries(window_results):\n",
        "    # Quick line charts of cluster counts and average cluster size over time.\n",
        "\n",
        "    if not window_results:\n",
        "        return\n",
        "\n",
        "    # edited the below line with AI\n",
        "    dates = [w[\"end\"] for w in window_results]\n",
        "    num_clusters = [len(w[\"clusters\"]) for w in window_results]\n",
        "    avg_size = []\n",
        "\n",
        "    for w in window_results:\n",
        "        sizes = [len(c) for c in w[\"clusters\"]]\n",
        "        if sizes:\n",
        "            avg_size.append(sum(sizes) / len(sizes))\n",
        "        else:\n",
        "            avg_size.append(0)\n",
        "\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.plot(dates, num_clusters, marker=\"o\")\n",
        "    plt.title(\"Number of clusters over time\")\n",
        "    plt.xlabel(\"Window end date\")\n",
        "    plt.ylabel(\"Cluster count\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.plot(dates, avg_size, marker=\"o\")\n",
        "    plt.title(\"Average cluster size over time\")\n",
        "    plt.xlabel(\"Window end date\")\n",
        "    plt.ylabel(\"Avg cluster size\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 8. Example driver function  (for testing)\n",
        "\n",
        "# I wrote this test case with the help of AI.\n",
        "\n",
        "def run_full_analysis(price_df, corr_threshold=0.6,\n",
        "                      window_size=None, step=None):\n",
        "    # Helper to run everything in one place for manual testing in a notebook.\n",
        "\n",
        "    # full-period analysis\n",
        "    full_returns = compute_log_returns(price_df)\n",
        "    full_corr = compute_correlation_matrix(full_returns)\n",
        "    full_mst = build_mst_from_corr(full_corr)\n",
        "    full_clusters = clusters_from_mst(full_mst,\n",
        "                                      corr_threshold=corr_threshold)\n",
        "    full_summary = summarize_clusters(full_corr, full_clusters)\n",
        "\n",
        "    print(\"Full-sample cluster summary:\")\n",
        "    print(full_summary)\n",
        "\n",
        "    plot_mst_graph(full_mst, full_clusters, title=\"Full-period MST\")\n",
        "    plot_clustered_heatmap(full_corr, full_clusters,\n",
        "                           title=\"Full-period clustered corr\")\n",
        "    plot_cluster_time_series(price_df, full_clusters)\n",
        "\n",
        "    # optional rolling-window analysis\n",
        "    if window_size is not None and step is not None:\n",
        "        windows = rolling_window_analysis(\n",
        "            price_df,\n",
        "            window_size=window_size,\n",
        "            step=step,\n",
        "            corr_threshold=corr_threshold,\n",
        "        )\n",
        "        plot_window_summaries(windows)\n",
        "\n",
        "        # show the first window's clustered heatmap\n",
        "        first = windows[0]\n",
        "        title = f\"First window clustered corr: {first['start']} to {first['end']}\"\n",
        "        plot_clustered_heatmap(first[\"corr\"], first[\"clusters\"],\n",
        "                               title=title)\n",
        "\n",
        "    # return objects in case we want to inspect them\n",
        "    return {\n",
        "        \"corr\": full_corr,\n",
        "        \"mst\": full_mst,\n",
        "        \"clusters\": full_clusters,\n",
        "        \"summary\": full_summary,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LqUiVb6RmRw4"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}